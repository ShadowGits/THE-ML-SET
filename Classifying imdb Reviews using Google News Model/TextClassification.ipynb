{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_val_split=tfds.Split.TRAIN.subsplit([6,4])\n",
    "\n",
    "(train_data,validation_data),test_data=tfds.load(\n",
    "    name=\"imdb_reviews\",\n",
    "    split=(('train[:60%]','train[60%:]'),'test'),\n",
    "    as_supervised=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'This is a big step down after the surprisingly enjoyable original. This sequel isn\\'t nearly as fun as part one, and it instead spends too much time on plot development. Tim Thomerson is still the best thing about this series, but his wisecracking is toned down in this entry. The performances are all adequate, but this time the script lets us down. The action is merely routine and the plot is only mildly interesting, so I need lots of silly laughs in order to stay entertained during a \"Trancers\" movie. Unfortunately, the laughs are few and far between, and so, this film is watchable at best.'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b\"Perhaps because I was so young, innocent and BRAINWASHED when I saw it, this movie was the cause of many sleepless nights for me. I haven't seen it since I was in seventh grade at a Presbyterian school, so I am not sure what effect it would have on me now. However, I will say that it left an impression on me... and most of my friends. It did serve its purpose, at least until we were old enough and knowledgeable enough to analyze and create our own opinions. I was particularly terrified of what the newly-converted post-rapture Christians had to endure when not receiving the mark of the beast. I don't want to spoil the movie for those who haven't seen it so I will not mention details of the scenes, but I can still picture them in my head... and it's been 19 years.\">, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Hood of the Living Dead had a lot to live up to even before the opening credits began. First, any play on \"...of the living dead\" invokes His Holiness Mr. Romero and instantly sets up a high standard to which many movies cannot afford to aspire. And second, my movie-watching companion professed doubt that any urban horror film would surpass the seminal Leprechaun In the Hood. Skeptical, we settled in to watch. <br /><br />We were rewarded with a surprisingly sincere and good-hearted zombie film. Oh, certainly the budget is low, and of course the directors\\' amateurs friends populate the cast, but Hood of the Living Dead loves zombie cinema. Cheap? Yeah. But when it\\'s this cheap, you can clearly see where LOVE holds it together. <br /><br />Ricky works in a lab during the day and as a surrogate parent to his younger brother at night. He dreams of moving out of Oakland. Before this planned escape, however, his brother is shot to death in a drive-by. Ricky\\'s keen scientific mind presents an option superior to CPR or 911: injections of his lab\\'s experimental regenerative formula. Sadly, little bro wakes up in an ambulance as a bloodthirsty Oakland zombie! Chaos and mayhem! I think it\\'s more economical to eat your enemies than take vengeance in a drive-by, but then again, I\\'m a poor judge of the complexities of urban life. (How poor a judge? In response to a gory scene involving four men, I opined \"Ah-ha! White t-shirts on everyone so the blood shows up. Economical! I used the same technique in my own low-budget horror film.\" Jordan replied, \"No, that\\'s gang dress. White t-shirts were banned from New Orleans bars for a time as a result.\" Oh.)<br /><br />A lot of the movie is set in someone\\'s living room, so there\\'s a great deal of hanging out and waiting for the zombies. But the characters are sympathetic and the movie is sincere-- it surpasses its budget in spirit. <br /><br />Zombie explanation: When man plays God, zombies arise! Or, perhaps: Follow FDA-approved testing rules before human experimentation! <br /><br />Contribution to the zombie canon: This is the first zombie movie I\\'ve seen with a drive-by shooting. As far as the actual zombies go, infection is spread with a bite as usual, but quite unusually head shots don\\'t work-- it\\'s heart shots that kill. Zombies have pulses, the absence of which proves true death. And these zombies make pretty cool jaguar-growl noises. <br /><br />Gratuitous zombie movie in-joke: A mercenary named Romero. Groan. <br /><br />Favorite zombie: Jaguar-noise little brother zombie, of course!'>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b\"For me this is a story that starts with some funny jokes regarding Franks fanatasies when he is travelling with a staircase and when he is sitting in business meetings... The problem is that when you have been watching this movie for an hour you will see the same fantasies/funny situations again and again and again. It is to predictable. It is more done as a TV story where you can go away and come back without missing anything.<br /><br />I like Felix Herngren as Frank but that is not enough even when it is a comedy it has to have more variations and some kind of message to it's audience....<br /><br />\">, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in train_data.take(4):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 1, 0, 1, 0, 1, 1, 1, 0], dtype=int64)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Expore data\n",
    "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
    "train_labels_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 20), dtype=float32, numpy=\n",
       "array([[ 2.209591  , -2.7093675 ,  3.6802928 , -1.0291991 , -4.1671185 ,\n",
       "        -2.4566064 , -2.2519937 , -0.36589956,  1.9485804 , -3.1104462 ,\n",
       "        -2.4610963 ,  1.3139242 , -0.9161584 , -0.16625322, -3.723651  ,\n",
       "         1.8498232 ,  3.499562  , -1.2373022 , -2.8403084 , -1.213074  ],\n",
       "       [ 1.9055302 , -4.11395   ,  3.6038654 ,  0.28555924, -4.658998  ,\n",
       "        -5.5433393 , -3.2735848 ,  1.9235417 ,  3.8461034 ,  1.5882455 ,\n",
       "        -2.64167   ,  0.76057523, -0.14820506,  0.9115291 , -6.45758   ,\n",
       "         2.3990374 ,  5.0985413 , -3.2776263 , -3.2652326 , -1.2345369 ],\n",
       "       [ 3.6510668 , -4.7066135 ,  4.71003   , -1.7002777 , -3.7708545 ,\n",
       "        -3.709126  , -4.222776  ,  1.946586  ,  6.1182513 , -2.7392752 ,\n",
       "        -5.4384456 ,  2.7078724 , -2.1263676 , -0.7084146 , -5.893995  ,\n",
       "         3.1602864 ,  3.8389287 , -3.318196  , -5.1542974 , -2.4051712 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Embed text into values\n",
    "#usinf google news embedding model\n",
    "\n",
    "embedding=\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer=hub.KerasLayer(embedding,input_shape=[],\n",
    "                        dtype=tf.string,trainable=True)\n",
    "hub_layer(train_examples_batch[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 400,373\n",
      "Trainable params: 400,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model outline\n",
    "\n",
    "model=tf.keras.Sequential([\n",
    "    hub_layer,\n",
    "    tf.keras.layers.Dense(16,activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model compiling\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.BinaryCrossentropy(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 - 4s - loss: 0.7998 - accuracy: 0.5374 - val_loss: 0.6800 - val_accuracy: 0.5623\n",
      "Epoch 2/10\n",
      "30/30 - 2s - loss: 0.6526 - accuracy: 0.6156 - val_loss: 0.6315 - val_accuracy: 0.6574\n",
      "Epoch 3/10\n",
      "30/30 - 2s - loss: 0.6066 - accuracy: 0.6801 - val_loss: 0.5894 - val_accuracy: 0.6921\n",
      "Epoch 4/10\n",
      "30/30 - 2s - loss: 0.5657 - accuracy: 0.7133 - val_loss: 0.5543 - val_accuracy: 0.7226\n",
      "Epoch 5/10\n",
      "30/30 - 2s - loss: 0.5280 - accuracy: 0.7462 - val_loss: 0.5236 - val_accuracy: 0.7470\n",
      "Epoch 6/10\n",
      "30/30 - 3s - loss: 0.4928 - accuracy: 0.7705 - val_loss: 0.4936 - val_accuracy: 0.7690\n",
      "Epoch 7/10\n",
      "30/30 - 2s - loss: 0.4571 - accuracy: 0.7963 - val_loss: 0.4652 - val_accuracy: 0.7895\n",
      "Epoch 8/10\n",
      "30/30 - 2s - loss: 0.4233 - accuracy: 0.8188 - val_loss: 0.4367 - val_accuracy: 0.8065\n",
      "Epoch 9/10\n",
      "30/30 - 3s - loss: 0.3904 - accuracy: 0.8361 - val_loss: 0.4147 - val_accuracy: 0.8167\n",
      "Epoch 10/10\n",
      "30/30 - 3s - loss: 0.3612 - accuracy: 0.8487 - val_loss: 0.3933 - val_accuracy: 0.8270\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_data.shuffle(10000).batch(512),epochs=10,validation_data=validation_data.batch(512),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.174\n",
      "accuracy 0.932\n"
     ]
    }
   ],
   "source": [
    "#evaluate\n",
    "results=model.evaluate(test_data.batch(512),verbose=0)\n",
    "for name,value in zip(model.metrics_names,results):\n",
    "    print(\"%s %0.3f\"%(name,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
